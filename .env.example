# Supervisor Agent Configuration
# Copy this file to .env and fill in your actual values

# Tool execution timeout in seconds - increased for complex LLM operations
TOOL_EXECUTION_TIMEOUT=900

# Data directory - base path for all data files (Cedant Loss Data, Historical Event DB, etc.)
DATA_DIR=data/public-sample-data

# LLM Configuration
# LLM_MODEL: Used for complex tasks like submission pack parsing
# LLM_MODEL_FAST: Used for most tasks (agent activities, general workflows)
# 
# For OpenAI:
# LLM_MODEL=openai/gpt-4
# LLM_MODEL_FAST=gpt-4o-mini
# LLM_KEY=your_openai_api_key_here
#
# For AWS Bedrock (Claude):
# LLM_MODEL=bedrock/us.anthropic.claude-opus-4-5-20251101-v1:0
# LLM_MODEL_FAST=bedrock/us.anthropic.claude-haiku-4-5-20251001-v1:0
# LLM_KEY=your_bedrock_api_key_here
# AWS_REGION_NAME=us-east-1
LLM_MODEL=your_llm_model_here
LLM_MODEL_FAST=your_fast_llm_model_here
LLM_KEY=your_api_key_here

# AWS Bedrock Configuration (if using Bedrock)
AWS_REGION_NAME=us-east-1

# Suppress LiteLLM verbose output
LITELLM_LOG=ERROR

# NumPy Configuration - Prevent CPU dispatcher re-initialization in Temporal workflows
NUMPY_DISABLE_CPU_FEATURES=1
OMP_NUM_THREADS=1

# Temporal Configuration
TEMPORAL_TASK_QUEUE=submission-pack-task-queue
# Set to CRITICAL to suppress warnings, INFO for more verbose logging
TEMPORAL_LOG_LEVEL=CRITICAL
# Suppress Temporal Rust SDK warnings (error, warn, info, debug, trace)
RUST_LOG=error

# Temporal Cloud Configuration
TEMPORAL_ADDRESS=your_temporal_address_here
TEMPORAL_NAMESPACE=your_temporal_namespace_here
TEMPORAL_API_KEY=your_temporal_api_key_here
